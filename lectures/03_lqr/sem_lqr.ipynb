{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzLN6qz8gEcU"
      },
      "source": [
        "## Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cztw2TAOgCTk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import math\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_1d(data, xlabel = \"timestamp\", ylabel = \"\"):\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    plt.plot(data)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.show()\n",
        "\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import math\n",
        "from matplotlib import rc\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "def animate(trajectory, axes_limits=[-5, 5, -5, 5], frames = 50, step = 1):\n",
        "    x_hist_, y_hist_, _ = trajectory\n",
        "\n",
        "    x_hist = x_hist_[::step]\n",
        "    y_hist = y_hist_[::step]\n",
        "\n",
        "    plt.ioff()\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 4))\n",
        "    ax.axis(axes_limits)\n",
        "    ax.set_aspect(\"equal\")\n",
        "\n",
        "    point1, = ax.plot(0,1, marker=\"o\", label=\"location\")\n",
        "    ax.legend()\n",
        "    ax.grid()\n",
        "    ax.set_xlabel(\"$x$\")\n",
        "\n",
        "    def update(t):\n",
        "        x = x_hist[int(t) % len(x_hist)]\n",
        "\n",
        "        point1.set_data([x],[0])\n",
        "\n",
        "        return point1,\n",
        "\n",
        "    ani = FuncAnimation(fig, update, interval=1000/24, blit=True, repeat=True,\n",
        "                    frames=frames)\n",
        "    plt.ion()\n",
        "\n",
        "    return ani"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ea6cFcqELJVV"
      },
      "source": [
        "# Linear Quadratic Regulator\n",
        "\n",
        "## Context\n",
        "\n",
        "Let us consider a linear system $\\dot{x} = A x + B u$\n",
        "\n",
        "During today's seminar we will focus on a way to synthesize full-state feedback $u = - K x$ for this system that will minimize quadratic cost in the form of $\\int_{0}^{\\infty} x^T Q x + u^T R u \\, dt$.\n",
        "\n",
        "The properties of linear systems allow for the derivation of the controllers of such type, which is extremely handy in cases when the onboard computational resources are limited and at the same time some kind of optimality is required. In contrast to PID controllers, that could require manual tuning, there is a closed form for the LQ controller that stabilizes the system and (informally speaking) keeps the energy consumption of the controller reasonable.\n",
        "\n",
        "MPC on the other hand can handle extremely difficult problems, such as non-convex state and control limitations and a wide range of non-linear objectives, but it comes with the cost of finite planning horizon and heavy computational burden on the robot's computer.\n",
        "\n",
        "However, it should be noticed that LQR and MPC are neither polar opposites, nor two incompatible approaches. Discrete finite-horizon LQR is essentially linear MPC.\n",
        "\n",
        "## Problem statement and assumptions\n",
        "\n",
        "Let us express the desired controller in the closed form, reducing a problem to number of matrix multiplications.\n",
        "\n",
        "First, let us state the problem in terms of the requirements to all the matrices and provide some explanation to their meaning.\n",
        "\n",
        "We will consider a system with the state dynamics of $\\dot{x} = A x + B u$, where $x$ is n-dimensional and $u$ is m-dimensional. Please keep the shapes of all the matrices in mind during the derivation.\n",
        "\n",
        "The problem of stabilizing the system, i.e. bringing the state $x$ to zero, will be considered.\n",
        "\n",
        "Along the way we are going to minimize the cost functional $J$ that is given by $\\int_{0}^{\\infty} x^T Q x + u^T R u \\, dt$. Why such a form was chosen? First, this quadratic cost will be equal to zero if the deviation from the desired state is absent and the control effort is zero as well. Second, the properties of the quadratic functions allow for a handful of useful of minimization techniques.\n",
        "\n",
        "Let us closely examine the cost finctional. We will assume the matrix $Q$ to be symmetric positive semi-definite, meaning $x^T Q x \\geq 0$ for any $x$. It makes sense to do so, because otherwise there will be states that deviate from the desired and at the same time decrease the functional that we consider to be a \"cost\" of the state-action trajectory in the episode.\n",
        "\n",
        "Second, we will assume matrix $R$ to be positive-definite. Otherwise there will be some non-zero control outputs that do not cost anything or even have negative cost, which is on the conceptual level equivalent to some speed and steering of the car that result in the tank filling up with fuel.\n",
        "\n",
        "## Derivation\n",
        "\n",
        "Now let us add a term to the cost function and instantly subtract it, which will not change its value. We require the matrix P to be symmetrical here, although it is not known yet.\n",
        "\n",
        "$J = \\int_{0}^{\\infty} [x^T Q x + u^T R u \\,] \\ dt = x_0^T P x_0 - x_0^T P x_0 + \\int_{0}^{\\infty} [x^T Q x + u^T R u \\,] dt = $\n",
        "\n",
        "Let us move $- x_0^T P x_0$ under the integral:\n",
        "\n",
        "$= x_0^T P x_0 + \\int_{0}^{\\infty} [\\frac{d}{dt} x^T P x + x^T Q x + u^T R u \\,] dt = $\n",
        "\n",
        "Then let us expand the first term under the integral with the product rule:\n",
        "\n",
        "$= x_0^T P x_0 + \\int_{0}^{\\infty} ]\\dot{x}^T P x + x^T P \\dot{x} + x^T Q x + u^T R u \\,] dt = $\n",
        "\n",
        "Now let us substitute $\\dot{x}$ with the right hand-side of the system dynamics:\n",
        "\n",
        "$= x_0^T P x_0 + \\int_{0}^{\\infty} ](A x + B u)^T P x + x^T P (A x + B u) + x^T Q x + u^T R u \\,] dt = $\n",
        "\n",
        "After that a couple of square completions gives\n",
        "\n",
        "$= x_0^T P x_0 + \\int_{0}^{\\infty} [x^T (A^T P + P A + Q - P B R^{-1} B^T P) x + (u + R^{-1} B^T P x)^T R (u + R^{-1} B^T P x) \\,] dt$\n",
        "\n",
        "Now let us carefully examine this result.\n",
        "\n",
        "First, there are two terms here: the first one and the integral. Let us recall that **the overall value of the cost does not depend on the choice of matrix $P$**.\n",
        "\n",
        "The matrix $P$ can be chosen such that it satisfies the Algebraic Riccati Equation $A^T P + P A + Q - P B R^{-1} B^T P = 0$.\n",
        "\n",
        "The cost then takes form of\n",
        "\n",
        "$x_0^T P x_0 + \\int_{0}^{\\infty} [(u + R^{-1} B^T P x)^T R (u + R^{-1} B^T P x) \\,] dt$\n",
        "\n",
        "Since R is positive definite and since the first term does not depend on the control $u$, the cost will be minimized if the control is precisely $u = - R^{-1} B^T P x$, which is exactly the full state feedback that we are looking for ($K = R^{-1} B^T P$).\n",
        "\n",
        "Equation $A^T P + P A + Q - P B R^{-1} B^T P = 0_{n \\times n}$ is a matrix Algebraic Riccati Equation (ARE). It becomes rather sophisticated to solve it by hand even for relatively small systems. Luckily enough, there are software tools that solve them automatically.\n",
        "\n",
        "With this in mind, let us consider a specific system with simple linear dynamics. The plan for the rest is the following:\n",
        "- a system with 1 degree of freedom (point with mass) will be considered\n",
        "- simple PD feedback will be implemented and assessed in terms of the cost of the state-action trajectory\n",
        "- LQR (continious and infinite-time!) will be applied to the same problem (which is discrete and finite-time)\n",
        "- solving Algebraic Riccati Equations with scipy will be considered\n",
        "- LQR will be applied to more complex systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFraDSuahP0t"
      },
      "source": [
        "## Simulating a system\n",
        "\n",
        "Let us consider a system with a mass moving horizontally without friction along one axis.\n",
        "\n",
        "$x = \\begin{pmatrix}\n",
        "p \\\\\n",
        "\\dot{p}\n",
        "\\end{pmatrix}\n",
        "$, where $p$ stands for position\n",
        "\n",
        "Let us control this system by exerting force onto it.\n",
        "\n",
        "$u = \\begin{pmatrix}\n",
        "F\n",
        "\\end{pmatrix}\n",
        "$\n",
        "\n",
        "The continuous system dynamics in such a case will take the form of\n",
        "\n",
        "$\\dot{x} = \\begin{pmatrix}\n",
        "\\dot{p} \\\\\n",
        "\\ddot{p}\n",
        "\\end{pmatrix}$\n",
        "$ = A x + B u\n",
        " =$\n",
        "$ \\begin{pmatrix}\n",
        "0 & 1 \\\\\n",
        "0 & 0\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "p \\\\\n",
        "\\dot{p}\n",
        "\\end{pmatrix} +\n",
        "\\begin{pmatrix}\n",
        "0 \\\\\n",
        "\\frac{1}{m}\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "F\n",
        "\\end{pmatrix}\n",
        "$\n",
        "\n",
        "Later some changes to the system dynamics will be introduces. They will stay in the same framework of system description.\n",
        "\n",
        "Please examine the code below that does the following:\n",
        "- describes the system behaviour in the presence of the control signal\n",
        "- runs the simulation for a given number of episodes\n",
        "- visualizes the state and action trajectory, as well as the phase trajectory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mV-BnhikhPCr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Dyn_block_1D:\n",
        "    def __init__(self, A, B, x0, v0, dt):\n",
        "        self.x = np.array([[x0], [v0]])\n",
        "\n",
        "        self.m = m\n",
        "        self.dt = dt\n",
        "\n",
        "        self.A = A\n",
        "\n",
        "        self.B = B\n",
        "\n",
        "    def sys_dyn(self, u):\n",
        "        xdot = self.A @ self.x + self.B @ u\n",
        "\n",
        "        return xdot\n",
        "\n",
        "    def integrate(self, xdot):\n",
        "        self.x += xdot * self.dt\n",
        "\n",
        "    def get_state(self):\n",
        "        return self.x\n",
        "\n",
        "def run_block_simulation(A, B, x0, v0, dt, num_episodes, control_function):\n",
        "    block = Dyn_block_1D(A, B, x0, v0, dt)\n",
        "\n",
        "    x_traj = []\n",
        "    v_traj = []\n",
        "    u_traj = []\n",
        "\n",
        "    for i in range(num_episodes):\n",
        "        x = block.get_state()\n",
        "\n",
        "        control = control_function(i, x)\n",
        "\n",
        "        x_traj.append(x[0, 0])\n",
        "        v_traj.append(x[1, 0])\n",
        "        u_traj.append(control)\n",
        "\n",
        "        x_dot = block.sys_dyn(np.array([[control]]))\n",
        "\n",
        "        block.integrate(x_dot)\n",
        "\n",
        "    return x_traj, v_traj, u_traj\n",
        "\n",
        "def run_and_visualize_block(A, B, x0, v0, dt, num_episodes, control_function):\n",
        "    x_hist, v_hist, u_hist = run_block_simulation(A = A, B = B, x0 = x0, v0 = v0, dt = dt,\n",
        "                        num_episodes = num_episodes, control_function = control_function)\n",
        "\n",
        "    plot_1d(x_hist, ylabel = \"p\")\n",
        "    plot_1d(v_hist, ylabel = \"p_dot\")\n",
        "    plot_1d(u_hist, ylabel = \"control_force\")\n",
        "\n",
        "    plt.figure(figsize=(5, 3))\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.plot(x_hist, v_hist)\n",
        "    plt.xlabel(\"p\")\n",
        "    plt.ylabel(\"p_dot\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return (x_hist, v_hist, u_hist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBwVYbswlqQY"
      },
      "source": [
        "## Running the simulation\n",
        "\n",
        "There are some plots, that will help us to analyze the behaviour of the system. The first one is the displacement of the mass over time, the second is the velocity, the third is the commanded force.\n",
        "\n",
        "The fourth plot is the phase trajectory of the system, consisting of the connected dots with each of them representing a state where the system was at a certain moment in time.\n",
        "\n",
        "Lastly, there is an animation that you are already familiar with.\n",
        "\n",
        "Let us apply a simple control that will depend purely on time, not on the system state, and observe the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "G1olUOKi8aM3",
        "outputId": "1c1ed0d0-44fb-44cd-fcdb-9a3380d025d2"
      },
      "outputs": [],
      "source": [
        "def sin_control(i, x):\n",
        "    return 20 * np.sin(i / 8.0)\n",
        "\n",
        "A = np.array([[0.0, 1.0],\n",
        "              [0.0, 0.0]])\n",
        "\n",
        "m  = 1.0\n",
        "\n",
        "B = np.array([[0.0],\n",
        "              [1.0 / m]])\n",
        "\n",
        "x0 = 1.0\n",
        "v0 = 0.0\n",
        "dt = 0.01\n",
        "\n",
        "num_episodes = 300\n",
        "control_function = sin_control\n",
        "\n",
        "trajectory_sin = run_and_visualize_block(A = A, B = B, x0 = x0, v0 = v0, dt = dt, num_episodes = num_episodes, control_function = control_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "cNP5sRddoe0C",
        "outputId": "e527ab19-847b-4574-91dc-10da79c9be92"
      },
      "outputs": [],
      "source": [
        "animate(trajectory_sin, frames = num_episodes, step=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALc-2jac17FF"
      },
      "source": [
        "## State-action trajectory cost\n",
        "\n",
        "Another important part of the control algorithm development is the ability to evaluate the performance of the controller. One of the ways to do so is to measure the approximation of the cost $J$ used in the derivation above. The approximation that will be used is $\\hat{J} = \\sum_{0}^{N} (x_i^T Q x_i + u_i^T R u_i) \\Delta t$.\n",
        "\n",
        "Please complete the implementation of this function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2fZE_5BqWdt"
      },
      "outputs": [],
      "source": [
        "def evaluate_state_action_trajectory(trajectory, Q, R, dt):\n",
        "    xtr, vtr, utr = trajectory\n",
        "\n",
        "    cost, cx, cu = 0, 0, 0\n",
        "\n",
        "    for i in range(len(xtr)):\n",
        "        xvec = np.array([[xtr[i]],\n",
        "                         [vtr[i]]])\n",
        "\n",
        "        uvec = np.array([[utr[i]]])\n",
        "\n",
        "        # YOUR CODE BELOW\n",
        "        \n",
        "        curr_cost = (xvec.T @ Q @ xvec + uvec.T @ R @ uvec) * dt\n",
        "        \n",
        "        cx += xvec.T @ Q @ xvec * dt\n",
        "        cu += uvec.T @ R @ uvec * dt\n",
        "\n",
        "        # YOUR CODE ABOVE\n",
        "\n",
        "        cost += curr_cost\n",
        "\n",
        "    return cost, cx, cu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9wnrVRb45FR",
        "outputId": "f05d4512-c0b2-4f05-fb3c-47a7bbbeea43"
      },
      "outputs": [],
      "source": [
        "Q = np.array([[1, 0],\n",
        "              [0, 1]])\n",
        "\n",
        "R = np.eye(1) * 1\n",
        "\n",
        "traj_cost, cx, cu = evaluate_state_action_trajectory(trajectory_sin, Q, R, dt)\n",
        "\n",
        "print(traj_cost, cx, cu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec-VMvQt45ra"
      },
      "source": [
        "## Proportional-Differential controller\n",
        "\n",
        "Can you think of a better way to stabilize the system, than the sinosuidal signal, that in reality will not drive it to zero? Please implement a PD negative feedback in the form of $F = - K_p p - K_d \\dot{p}$. Compare the cost with the one that the sinosuidal controller ended up with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oLwp6_PM4hBa",
        "outputId": "cf5fa595-2ca0-45a6-b5fc-8d26709fdb2f"
      },
      "outputs": [],
      "source": [
        "def PD_control(i, x):\n",
        "    # YOUR CODE BELOW\n",
        "    u = - 3 * x[0, 0] - 1 * x[1, 0]\n",
        "    # YOUR CODE ABOVE\n",
        "\n",
        "    return u\n",
        "\n",
        "A = np.array([[0.0, 1.0],\n",
        "              [0.0, 0.0]])\n",
        "\n",
        "m = 1.0\n",
        "\n",
        "B = np.array([[0.0],\n",
        "              [1.0 / m]])\n",
        "\n",
        "x0 = 1.0\n",
        "v0 = 0.3\n",
        "dt = 0.01\n",
        "\n",
        "num_episodes = 1300\n",
        "control_function = PD_control\n",
        "\n",
        "trajectory_PD = run_and_visualize_block(A = A, B = B, x0 = x0, v0 = v0, dt = dt, num_episodes = num_episodes, control_function = control_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "khHcG6DSQOww",
        "outputId": "3f2f43c0-882e-4c07-a348-5c7cea023b47"
      },
      "outputs": [],
      "source": [
        "animate(trajectory_PD, frames = num_episodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXCVlNXHQdWy",
        "outputId": "773eabfd-54e7-4e1a-a466-3b84d5370d36"
      },
      "outputs": [],
      "source": [
        "Q = np.array([[1, 0],\n",
        "              [0, 1]])\n",
        "\n",
        "R = np.eye(1) * 1\n",
        "\n",
        "traj_cost, cx, cu = evaluate_state_action_trajectory(trajectory_PD, Q, R, dt)\n",
        "\n",
        "print(traj_cost, cx, cu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlajK8kLSCLZ"
      },
      "source": [
        "## Linear Quadratic Regulator\n",
        "\n",
        "Let us recall that LQR feedback has the form of $u = - R^{-1} B^T P x$, where $P$ is the solution of an Algebraic Riccati Equation $A^T P + P A + Q - P B R^{-1} B^T P = 0_{n \\times n}$.\n",
        "\n",
        "For the given system\n",
        "\n",
        "$A =\n",
        " \\begin{pmatrix}\n",
        "0 & 1 \\\\\n",
        "0 & 0\n",
        "\\end{pmatrix}$\n",
        "\n",
        "$B =\n",
        "\\begin{pmatrix}\n",
        "0 \\\\\n",
        "\\frac{1}{m}\n",
        "\\end{pmatrix}\n",
        "$\n",
        "\n",
        "And P could be presented in the form of\n",
        "\n",
        "$P =\n",
        "\\begin{pmatrix}\n",
        "p_1 & p_2 \\\\\n",
        "p_2 & p_3\n",
        "\\end{pmatrix}$\n",
        "\n",
        "taking into account its property of being symmetric.\n",
        "\n",
        "In the explicit form ARE reads\n",
        "\n",
        "$\\begin{pmatrix}\n",
        "0 & 0 \\\\\n",
        "1 & 0\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "p_1 & p_2 \\\\\n",
        "p_2 & p_3\n",
        "\\end{pmatrix} +\n",
        "\\begin{pmatrix}\n",
        "p_1 & p_2 \\\\\n",
        "p_2 & p_3\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "0 & 1 \\\\\n",
        "0 & 0\n",
        "\\end{pmatrix} + Q +\n",
        "\\begin{pmatrix}\n",
        "p_1 & p_2 \\\\\n",
        "p_2 & p_3\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "0 \\\\\n",
        "\\frac{1}{m}\n",
        "\\end{pmatrix}\n",
        "R^{-1}\n",
        "\\begin{pmatrix}\n",
        "0 & \\frac{1}{m}\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "p_1 & p_2 \\\\\n",
        "p_2 & p_3\n",
        "\\end{pmatrix} =\n",
        "\\begin{pmatrix}\n",
        "0 & 0\\\\\n",
        "0 & 0\n",
        "\\end{pmatrix}\n",
        "$\n",
        "\n",
        "Voluntarely assuming the mass to be equal to one and setting $Q$ and $R$ to be identity matrices of proper dimensions (exactly as they appear in the code), we can reformulate this equation as\n",
        "\n",
        "$\n",
        "\\begin{pmatrix}\n",
        "1 - p_2^2 & p_1 - p_2 p_3\\\\\n",
        "p_1 - p_2 p_3 & 2 p_2 - p_3^2 + 1\n",
        "\\end{pmatrix} =\n",
        "\\begin{pmatrix}\n",
        "0 & 0\\\\\n",
        "0 & 0\n",
        "\\end{pmatrix}\n",
        "$\n",
        "\n",
        "Getting rid of the solutions that stabilize the system at negative time, we finally get\n",
        "\n",
        "$P =\n",
        "\\begin{pmatrix}\n",
        "\\sqrt{3} & 1 \\\\\n",
        "1 & \\sqrt{3}\n",
        "\\end{pmatrix}$\n",
        "\n",
        "Which results in the feedback gain matrix $K = R^{-1} B^T P = \\begin{pmatrix} 1 & \\sqrt{3} \\end{pmatrix}$ and the feedback law $u = - p - \\sqrt{3} \\dot{p}$.\n",
        "\n",
        "Moreover, it is now possible to calculate the exact value of the cost function (see the end on the controller derivation), because it is formulated in terms of the $P$ matrix.\n",
        "\n",
        "For the given initial state of $x_0 = \\begin{pmatrix}\n",
        "1 \\\\\n",
        "0.3\n",
        "\\end{pmatrix}$\n",
        "\n",
        "the cost is equal to $x_0^T P x_0 \\approx 2.49$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ztZvtoBgREuD",
        "outputId": "d5395dda-d74b-47ce-b207-4f38121e6135"
      },
      "outputs": [],
      "source": [
        "Q = np.array([[1, 0],\n",
        "              [0, 1]])\n",
        "\n",
        "R = np.eye(1) * 1\n",
        "\n",
        "A = np.array([[0.0, 1.0],\n",
        "              [0.0, 0.0]])\n",
        "\n",
        "P = np.array([[math.sqrt(3), 1],\n",
        "              [1, math.sqrt(3)]])\n",
        "\n",
        "m  = 1.0\n",
        "\n",
        "B = np.array([[0],\n",
        "              [1 / m]])\n",
        "\n",
        "def LQR_control(i, x):\n",
        "    # YOUR CODE BELOW\n",
        "    \n",
        "    K = np.linalg.inv(R) @ B.T @ P\n",
        "\n",
        "    # YOUR CODE ABOVE\n",
        "\n",
        "    u = - K @ x\n",
        "\n",
        "    #print(u)\n",
        "\n",
        "    return u[0, 0]\n",
        "\n",
        "x0 = 1.0\n",
        "v0 = 0.3\n",
        "dt = 0.01\n",
        "\n",
        "num_episodes = 1300\n",
        "control_function = LQR_control\n",
        "\n",
        "trajectory = run_and_visualize_block(A = A, B = B, x0 = x0, v0 = v0, dt = dt, num_episodes = num_episodes, control_function = control_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "g1_fohMBReKX",
        "outputId": "e3e38fef-7ec2-4367-ae37-e01627720bee"
      },
      "outputs": [],
      "source": [
        "animate(trajectory, frames = num_episodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mw2DG2DvkNS"
      },
      "source": [
        "Let us evaluate the performance of this controller. Why is the exact value of the cost different from the theoretically obtained one?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLTqNhkZRegX",
        "outputId": "5455d3fc-141b-432b-fea5-838de925eaf4"
      },
      "outputs": [],
      "source": [
        "Q = np.array([[1, 0],\n",
        "              [0, 1]])\n",
        "\n",
        "R = np.eye(1) * 1\n",
        "\n",
        "traj_cost = evaluate_state_action_trajectory(trajectory, Q, R, dt)\n",
        "\n",
        "print(traj_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w42UIj9Ab2ET"
      },
      "source": [
        "## Solving ARE with software tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4WNUzrbb7Rm",
        "outputId": "f366e616-b4df-4a79-dd03-81ac384c983c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy import linalg\n",
        "\n",
        "A = np.array([[0, 1],\n",
        "              [0, 0]])\n",
        "\n",
        "B = np.array([[0],\n",
        "              [1]])\n",
        "\n",
        "Q = np.array([[1, 0],\n",
        "              [0, 1]])\n",
        "\n",
        "R = np.array([[1]])\n",
        "\n",
        "P = linalg.solve_continuous_are(A, B, Q, R)\n",
        "\n",
        "print(P)\n",
        "\n",
        "np.allclose(A.T @ P + P @ A - P @ B @ np.linalg.inv(R) @ B.T @ P, -Q)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN0MLZvIxMD-"
      },
      "source": [
        "## The impact of the parameters on the cost and on the state-action trajectory\n",
        "\n",
        "Now let us perform a series of experiments with varying the parameters and the values in the $Q$ and $R$ matrices. But first, let us wrap the whole simulation in a single function for convenience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sulQqNK8wuak"
      },
      "outputs": [],
      "source": [
        "def run_visualize_evaluate_LQR_controller(A, B, Q_multiplier, R_multiplier, num_episodes,\n",
        "                                          dt, x0, v0):\n",
        "    Q = np.array([[1, 0],\n",
        "                  [0, 1]]) * Q_multiplier\n",
        "\n",
        "    R = np.eye(1) * R_multiplier\n",
        "\n",
        "    P = linalg.solve_continuous_are(A, B, Q, R)\n",
        "\n",
        "    # INSERT YOUR CODE FROM ABOVE HERE\n",
        "\n",
        "    # INSERT YOUR CODE FROM ABOVE HERE\n",
        "\n",
        "    print(K)\n",
        "\n",
        "    def LQR_control(i, x):\n",
        "        K = np.linalg.inv(R) @ B.T @ P\n",
        "\n",
        "        u = - K @ x\n",
        "\n",
        "        return u[0, 0]\n",
        "\n",
        "    control_function = LQR_control\n",
        "\n",
        "    trajectory = run_and_visualize_block(A = A, B = B, x0 = x0, v0 = v0, dt = dt,\n",
        "                      num_episodes = num_episodes, control_function = control_function)\n",
        "\n",
        "    traj_cost = evaluate_state_action_trajectory(trajectory, Q, R, dt)\n",
        "\n",
        "    print(traj_cost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_D2X7MCpyAVK",
        "outputId": "7d85c446-fd96-4381-bf4e-17ac465d8cd0"
      },
      "outputs": [],
      "source": [
        "A = np.array([[0.0, 1.0],\n",
        "              [0.0, 0.0]])\n",
        "\n",
        "m  = 1.0\n",
        "\n",
        "B = np.array([[0],\n",
        "              [1 / m]])\n",
        "\n",
        "num_episodes = 3000\n",
        "\n",
        "x0 = 1.0\n",
        "v0 = 0.3\n",
        "\n",
        "dt = 0.01\n",
        "\n",
        "run_visualize_evaluate_LQR_controller(A = A, B = B, Q_multiplier = 1, R_multiplier = 100,\n",
        "                                      num_episodes = num_episodes, dt = dt, x0 = x0, v0 = v0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcbvsX_t0YqK"
      },
      "source": [
        "Try changing the simulation parameters and answer the following questions:\n",
        "- Does the increase of the number of the simulation steps from $300$ to $1300$ change the total cost? Why so?\n",
        "- Does the increase of the number of the simulation steps from $1300$ to $13000$ change the total cost? Why so?\n",
        "\n",
        "Now please set the number of simulation steps to $3000$.\n",
        "\n",
        "- How does the change of the time step $\\Delta t$ from $0.01$ to $0.001$ along with a proper increase in the number of the simulation steps (in order to conserve the total duration of the episode) change the total cost? How exactly?\n",
        "- Try setting R_multiplier to $0.1$. What happened to the system trajectory? What happened to the gain matrix?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0oUn8An119b"
      },
      "source": [
        "## Spring-mass system\n",
        "\n",
        "Now let us connect the mass to the wall with a spring of stifness $k$. This will change the $A$ matrix to the following:\n",
        "\n",
        "$A =\n",
        "\\begin{pmatrix}\n",
        "0 & 1 \\\\\n",
        "-\\frac{k}{m} & 0\n",
        "\\end{pmatrix}$\n",
        "\n",
        "Try different values of $Q$ and $R$ matrices:\n",
        "- Default values of $1$ and $1$\n",
        "- With very expensive control\n",
        "- With very cheap control\n",
        "\n",
        "Examine the results and describe them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-DiR6pNjytea",
        "outputId": "5cfd96e5-b80f-4ded-ed77-57d2f1fa3458"
      },
      "outputs": [],
      "source": [
        "m  = 1.0\n",
        "k = 1.0\n",
        "\n",
        "A = np.array([[0.0, 1.0],\n",
        "              [- k / m, 0.0]])\n",
        "\n",
        "B = np.array([[0],\n",
        "              [1 / m]])\n",
        "\n",
        "num_episodes = 3000\n",
        "\n",
        "x0 = 1.0\n",
        "v0 = 0.3\n",
        "\n",
        "dt = 0.01\n",
        "\n",
        "run_visualize_evaluate_LQR_controller(A = A, B = B, Q_multiplier = 1, R_multiplier = 0.100,\n",
        "                                      num_episodes = num_episodes, dt = dt, x0 = x0, v0 = v0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY2ju54qdE40"
      },
      "source": [
        "### Home assignment\n",
        "\n",
        "1) apply LQR to the problem of stabilization of the system of two pendulums from the previous assignment. Does the optimal cost match with the best one you have obtained previously? Why?\n",
        "2) try decreasing $R$ matrix by a factor of 10. Did the system behaviour change? Why?\n",
        "3) apply LQR to the same system, but consisting of two inverted pendulums. Is the behaviour if the system generally same as for normal pendulums or not? Why?\n",
        "4) change $R$ matrix back and run the simulation. Did it qualitatively influence the behaviour if the system? Why?\n",
        "\n",
        "For each question a separate subsection should be created with the simulation plots and **elaborate answers** to the questions.\n",
        "\n",
        "1) примените LQR к задаче стабилизации системы из двух маятников из прошлой домашки. Совпадает ли стоимость оптимальной траектории с той, которая получалась без LQR? Почему?\n",
        "2) уменьшите значение матрицы $R$ в 10 раз. Как это повлияло на поведение системы?\n",
        "3) примените LQR к системе из двух обратных маятников, связанных пружиной. Похоже ли поведение системы на поведение системы из обычных маятников? Почему?\n",
        "4) увеличьте $R$ обратно и запустите симуляцию снова. Повлияло ли это качественно на поведение системы?\n",
        "\n",
        "Каждой подзадачи создайте пожалуйста отдельную подсекцию (в маркдауне можно писать заголовки с помощью значка решетки) с графиками поведения систем и подробными текстовыми ответами на вопросы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "dzLN6qz8gEcU"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
